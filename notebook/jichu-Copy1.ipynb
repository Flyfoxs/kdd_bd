{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import gc\n",
    "import datetime\n",
    "import itertools\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from tqdm import *\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.model_selection import KFold, RepeatedKFold,train_test_split,StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder,MinMaxScaler,StandardScaler\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, f1_score, log_loss,roc_auc_score,recall_score, precision_score\n",
    "import seaborn as sns\n",
    "color = sns.color_palette() \n",
    "sns.set(style=\"whitegrid\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.1'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install lightgbm==2.11\n",
    "lgb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_path(path):\n",
    "    file_name = []\n",
    "    for i in os.listdir(path):\n",
    "        c = i.split('_')[0]\n",
    "        file_name.append(c)\n",
    "    file_name = list(set(file_name))\n",
    "    return file_name\n",
    "def lgb_recall_score(y_true, pred,t):\n",
    "    pred[pred>=t] = 1\n",
    "    pred[pred<t] = 0\n",
    "    return recall_score(y_true, pred, average='binary')\n",
    "def lgb_precision_score(y_true, pred, t):\n",
    "    pred[pred>=t] = 1\n",
    "    pred[pred<t] = 0\n",
    "    return precision_score(y_true, pred, pos_label=0, average='binary')\n",
    "def auc(y,pred):\n",
    "    return roc_auc_score(y, pred)\n",
    "\n",
    "def f1(y,pred):\n",
    "    return f1_score(y, pred,average='macro')\n",
    "def lgb_f1_score(y_pred, y_val):\n",
    "    y_true = y_val.get_label()\n",
    "    y_pred[y_pred>=0.1] = 1\n",
    "    y_pred[y_pred<0.1] = 0\n",
    "    return 'f1', f1_score(y_true, y_pred, average='macro'), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_po_path = '../data/Motor_tain/Positive/'\n",
    "train_ne_path = '../data/Motor_tain/Negative/'\n",
    "train_po_file = get_path(train_po_path)\n",
    "train_ne_file = get_path(train_ne_path)\n",
    "test_path = '../data/Motor_testP/'\n",
    "test_file_name = get_path(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [01:03<00:00,  7.82it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:03<00:00,  7.61it/s]\n",
      " 33%|█████████████████████████▉                                                    | 1904/5738 [05:54<13:05,  4.88it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-a2419e1df11e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_po\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/train_jichu1.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_file_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/test_jichu1.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-a2419e1df11e>\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(file_name, file_path)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mfe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mdata_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_B.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mdata_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[1;34m'_F.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mfe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'idx'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinlan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinlan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinlan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1034\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinlan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinlan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m     \"\"\"\n\u001b[0;32m    813\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"基础特征\"\"\"\n",
    "def get_data(file_name,file_path):\n",
    "    fe = defaultdict(list)\n",
    "    for file in tqdm(file_name):\n",
    "        data_b = pd.read_csv(file_path + file + '_B.csv')\n",
    "        data_f = pd.read_csv(file_path + file +  '_F.csv')\n",
    "        fe['idx'].append(file)\n",
    "        \n",
    "        fe['ai1_max_b'].append(data_b.ai1.max())\n",
    "        fe['ai1_min_b'].append(data_b.ai1.min())\n",
    "        fe['ai1_mean_b'].append(data_b.ai1.mean())\n",
    "        fe['ai1_median_b'].append(data_b.ai1.median())\n",
    "        fe['ai1_mode_b'].append(data_b.ai1.value_counts().index[0])\n",
    "        fe['ai1_std_b'].append(data_b.ai1.std())\n",
    "        fe['ai1_kurt_b'].append(data_b.ai1.kurt())\n",
    "        \n",
    "        fe['ai2_max_b'].append(data_b.ai2.max())\n",
    "        fe['ai2_min_b'].append(data_b.ai2.min())\n",
    "        fe['ai2_mean_b'].append(data_b.ai2.mean())\n",
    "        fe['ai2_median_b'].append(data_b.ai2.median())\n",
    "        fe['ai2_mode_b'].append(data_b.ai2.value_counts().index[0])\n",
    "        fe['ai2_std_b'].append(data_b.ai2.std())\n",
    "        fe['ai2_kurt_b'].append(data_b.ai2.kurt())\n",
    "        \n",
    "        fe['ai1_max_f'].append(data_f.ai1.max())\n",
    "        fe['ai1_min_f'].append(data_f.ai1.min())\n",
    "        fe['ai1_mean_f'].append(data_f.ai1.mean())\n",
    "        fe['ai1_median_f'].append(data_f.ai1.median())\n",
    "        fe['ai1_mode_f'].append(data_f.ai1.value_counts().index[0])\n",
    "        fe['ai1_std_f'].append(data_f.ai1.std())\n",
    "        fe['ai1_kurt_f'].append(data_f.ai1.kurt())\n",
    "        \n",
    "        fe['ai2_max_f'].append(data_f.ai2.max())\n",
    "        fe['ai2_min_f'].append(data_f.ai2.min())\n",
    "        fe['ai2_mean_f'].append(data_f.ai2.mean())\n",
    "        fe['ai2_median_f'].append(data_f.ai2.median())\n",
    "        fe['ai2_mode_f'].append(data_f.ai2.value_counts().index[0])\n",
    "        fe['ai2_std_f'].append(data_f.ai2.std())\n",
    "        fe['ai2_kurt_f'].append(data_f.ai2.kurt())\n",
    "    return pd.DataFrame(fe)\n",
    "train = get_data(train_ne_file,train_ne_path)\n",
    "train['result'] = 0\n",
    "train_po = get_data(train_po_file,train_po_path)\n",
    "train_po['result'] = 1\n",
    "train = train.append(train_po).reset_index(drop=True)\n",
    "train.to_csv('../data/train_jichu1.csv', index=False)\n",
    "test = get_data(test_file_name,test_path)\n",
    "test.to_csv('../data/test_jichu1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train_jichu.csv')\n",
    "test = pd.read_csv('../data/test_jichu1.csv')\n",
    "for df in [train,test]:\n",
    "    df['std_b'] = df['ai1_std_b'] / df['ai2_std_b']\n",
    "    df['std_f'] = df['ai1_std_f'] / df['ai2_std_f']\n",
    "    df['ai1_ptp_b'] = df['ai1_max_b'] / df['ai1_min_b']\n",
    "    df['ai2_ptp_b'] = df['ai2_max_b'] / df['ai2_min_b']\n",
    "    df['ai1_ptp_f'] = df['ai1_max_f'] / df['ai1_min_f']\n",
    "    df['ai2_ptp_f'] = df['ai2_max_f'] / df['ai2_min_f']\n",
    "#     df['std_ai1_bf'] = df['ai1_std_b'] / df['ai1_std_f']\n",
    "#     df['std_ai2_bf'] = df['ai2_std_b'] / df['ai2_std_f']\n",
    "    df['ratio_b'] = df['ai1_ptp_b'] / df['ai2_ptp_b']\n",
    "    df['area_b'] = df['ai1_ptp_b'] * df['ai2_ptp_b']\n",
    "#     df['ratio_f'] = df['ai1_ptp_f'] / df['ai2_ptp_f']\n",
    "#     df['area_f'] = df['ai1_ptp_f'] * df['ai2_ptp_f']\n",
    "#     \"\"\"std/median\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['ai1_median_b']<train['ai1_median_b'].quantile(.3)]['result'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc = test[(test['ai1_median_b']<test['ai1_median_b'].quantile(.5))&(test['ai2_median_b']<test['ai2_median_b'].quantile(.5))]['idx'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sub = pd.read_csv('../S1_best_score.csv')\n",
    "sub[sub['idx'].isin(cc)]['result'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[(test['ai1_ptp_f']>test['ai1_ptp_f'].quantile(0.65))|(test['ai1_mean_f']<test['ai1_mean_f'].quantile(0.5))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['idx', 'ai1_max_b', 'ai1_min_b', 'ai1_mean_b', 'ai1_median_b',\n",
       "       'ai1_mode_b', 'ai1_std_b', 'ai1_kurt_b', 'ai2_max_b', 'ai2_min_b',\n",
       "       'ai2_mean_b', 'ai2_median_b', 'ai2_mode_b', 'ai2_std_b', 'ai2_kurt_b',\n",
       "       'ai1_max_f', 'ai1_min_f', 'ai1_mean_f', 'ai1_median_f', 'ai1_mode_f',\n",
       "       'ai1_std_f', 'ai1_kurt_f', 'ai2_max_f', 'ai2_min_f', 'ai2_mean_f',\n",
       "       'ai2_median_f', 'ai2_mode_f', 'ai2_std_f', 'ai2_kurt_f', 'result',\n",
       "       'std_b', 'std_f', 'ai1_ptp_b', 'ai2_ptp_b', 'ai1_ptp_f', 'ai2_ptp_f',\n",
       "       'ratio_b', 'area_b'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,12))\n",
    "# corr = train.corr() # 计算协方差 ,相关分析,皮尔逊相关系数\n",
    "# sns.heatmap(corr, xticklabels = corr.columns.values, \n",
    "#             yticklabels = corr.columns.values,annot=True) # 画热力图 \n",
    "# plt.show() # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# col_fe = [i for i in train.columns if i not in ['idx', 'result']+['ai2_std_b']]\n",
    "col_fe = [i for i in train.columns if i not in ['idx', 'result']]\n",
    "# col_fe = col+col2+col3+col1\n",
    "X_train = train[col_fe].copy()\n",
    "y_train = train['result'].copy()\n",
    "X_test = test[col_fe].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scale = MinMaxScaler()\n",
    "# scale.fit(X_train)\n",
    "# X_train = pd.DataFrame(scale.transform(X_train),columns=X_train.columns)\n",
    "# X_test = pd.DataFrame(scale.transform(X_test),columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5,3,1,0.6,0.9,0.08,2017,6:4400，+8'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 5\n",
    "seed = 996#2019,666\n",
    "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=seed)\n",
    "lgb_params = {\n",
    "                        'boosting_type': 'gbdt',\n",
    "                        'objective': 'binary',\n",
    "                        'metric': 'binary_logloss',#binary_logloss\n",
    "                        'is_unbalance': True,\n",
    "                        'max_depth': 5,#3\n",
    "                        'bagging_freq': 2,#5,3,2\n",
    "#                         'bagging_seed':1,\n",
    "#                         'lambda_l2': 2,\n",
    "                        'lambda_l1': 0.6,#1，0.2\n",
    "                        'subsample': 0.68,#0.7,0.8\n",
    "                        'colsample_bytree': 0.58,#0.5,0.7\n",
    "                        'learning_rate': 0.08,#0.02,0.1\n",
    "                        'seed': 2017,\n",
    "                        'nthread': 6,\n",
    "#                         'silent': True\n",
    "             }\n",
    "\"\"\"5,2,0.6,0.7,0.58,0.1,2017,6:4200\"\"\"\n",
    "\"\"\"5,2,0.6,0.68,0.58,0.08,2017,6:4200,+9\"\"\"\n",
    "\"\"\"5,2,0.6,0.85,0.08,2017,6:4400，+7\"\"\"\n",
    "\"\"\"5,3,1,0.6,0.9,0.08,2017,6:4400，+8\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[56]\ttraining's binary_logloss: 0.0302382\tvalid_1's binary_logloss: 0.0553004\n",
      "best iteration =  56\n",
      "fold 2\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[56]\ttraining's binary_logloss: 0.0353457\tvalid_1's binary_logloss: 0.0590651\n",
      "best iteration =  56\n",
      "fold 3\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[56]\ttraining's binary_logloss: 0.0230814\tvalid_1's binary_logloss: 0.0964808\n",
      "best iteration =  56\n",
      "fold 4\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[56]\ttraining's binary_logloss: 0.033219\tvalid_1's binary_logloss: 0.0362833\n",
      "best iteration =  56\n",
      "fold 5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[56]\ttraining's binary_logloss: 0.0358704\tvalid_1's binary_logloss: 0.0305404\n",
      "best iteration =  56\n",
      "recall_score :  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "precision_score :  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Wall time: 602 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "oof = np.zeros(len(X_train))\n",
    "predictions = np.zeros(len(X_test))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "score = []\n",
    "prec_score = []\n",
    "min_p = []\n",
    "for i, (train_index, val_index) in enumerate(skf.split(X_train,y_train)):\n",
    "    print(\"fold {}\".format(i+1))\n",
    "    X_tr, X_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_tr, y_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    lgb_train = lgb.Dataset(X_tr,y_tr)\n",
    "    lgb_val = lgb.Dataset(X_val,y_val)\n",
    "    num_round = 56#56\n",
    "    clf = lgb.train(lgb_params, lgb_train, num_round, valid_sets = [lgb_train, lgb_val],\n",
    "                     verbose_eval=250, early_stopping_rounds = 10#10\n",
    "                   )\n",
    "    oof[val_index] = clf.predict(X_val, num_iteration=clf.best_iteration)\n",
    "    print('best iteration = ',clf.best_iteration)\n",
    "    \n",
    "#     clf = AdaBoostClassifier(n_estimators=10, learning_rate=0.1, random_state=10)\n",
    "#     clf = AdaBoostClassifier(n_estimators=20, learning_rate=0.1, random_state=10)\n",
    "#     clf.fit(X_tr,y_tr)\n",
    "#     oof[val_index] = clf.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "#     r_score = lgb_recall_score(y_val.values, clf.predict_proba(X_val)[:, 1],0.0045)#0.23\n",
    "#     p_score = lgb_precision_score(y_val.values, clf.predict_proba(X_val)[:, 1],0.0045)\n",
    "    r_score = lgb_recall_score(y_val.values, oof[val_index],0.02312)#,0.23,0.0045,0.023,0.02312\n",
    "    p_score = lgb_precision_score(y_val.values, oof[val_index],0.02312)\n",
    "    score.append(r_score)\n",
    "    prec_score.append(p_score)\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = clf.feature_name() #col_fe\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance() #clf.feature_importances_\n",
    "    fold_importance_df[\"fold\"] = i + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "#     predictions += clf.predict_proba(X_test)[:, 1] / skf.n_splits\n",
    "    predictions += clf.predict(X_test, num_iteration=clf.best_iteration) / skf.n_splits\n",
    "print('recall_score : ', score)\n",
    "print('precision_score : ', prec_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4200\n",
      "1    1538\n",
      "Name: result, dtype: int64\n",
      "205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4100"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"lgbb_4200,lgb_\"\"\"\n",
    "sub = test[['idx']].copy()\n",
    "sub['result'] = predictions\n",
    "sub = sub.sort_values('result').reset_index(drop=True)\n",
    "sub.loc[:4200,'result'] = 0   #lgb  2000:0.3626,3000:0.5439,3200:0.5799,3500:0.6343,3750:0\n",
    "sub.loc[4200:,'result'] = 1\n",
    "sub['result'] = sub['result'].astype(int)\n",
    "# sub.to_csv('../sub/jichu_lgb4200.csv', index=False)\n",
    "print(sub['result'].value_counts())\n",
    "rr = pd.read_csv('../sub/aaa.csv')\n",
    "rr3 = rr[rr['result'] == 0]['idx'].tolist()\n",
    "print(len([i for i in sub[sub['result'] == 0]['idx'].tolist() if i not in rr3]))\n",
    "len(rr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catjj = pd.read_csv('../sub/S1_best_score.csv')\n",
    "cat3 = catjj[catjj['result'] == 1]['idx'].tolist()\n",
    "cc = sub[sub['idx'].isin(cat3)]['result']\n",
    "cc[cc==0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ai2_mean_f</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ai2_mean_b</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ai1_max_f</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ai1_ptp_f</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ai1_kurt_f</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ai1_mean_b</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>std_b</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ai2_median_b</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ai2_median_f</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ai1_min_f</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ai1_mean_f</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ai2_kurt_b</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ai1_median_b</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ai1_std_b</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ai1_kurt_b</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ai1_mode_b</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ai2_std_b</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>std_f</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ai2_mode_f</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ai1_mode_f</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ai2_kurt_f</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ai2_mode_b</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ratio_b</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>area_b</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ai2_std_f</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ai2_max_b</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ai2_min_b</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ai1_std_f</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ai1_min_b</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ai1_ptp_b</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ai1_median_f</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ai2_ptp_f</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ai2_min_f</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ai1_max_b</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ai2_ptp_b</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ai2_max_f</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Feature  importance\n",
       "0     ai2_mean_f        18.8\n",
       "1     ai2_mean_b        15.8\n",
       "2      ai1_max_f        10.8\n",
       "3      ai1_ptp_f        10.2\n",
       "4     ai1_kurt_f         8.0\n",
       "5     ai1_mean_b         5.6\n",
       "6          std_b         5.6\n",
       "7   ai2_median_b         5.6\n",
       "8   ai2_median_f         5.4\n",
       "9      ai1_min_f         4.2\n",
       "10    ai1_mean_f         3.8\n",
       "11    ai2_kurt_b         3.6\n",
       "12  ai1_median_b         3.2\n",
       "13     ai1_std_b         2.8\n",
       "14    ai1_kurt_b         2.0\n",
       "15    ai1_mode_b         1.8\n",
       "16     ai2_std_b         1.8\n",
       "17         std_f         1.6\n",
       "18    ai2_mode_f         1.4\n",
       "19    ai1_mode_f         1.4\n",
       "20    ai2_kurt_f         1.2\n",
       "21    ai2_mode_b         1.2\n",
       "22       ratio_b         1.2\n",
       "23        area_b         0.8\n",
       "24     ai2_std_f         0.8\n",
       "25     ai2_max_b         0.8\n",
       "26     ai2_min_b         0.6\n",
       "27     ai1_std_f         0.6\n",
       "28     ai1_min_b         0.6\n",
       "29     ai1_ptp_b         0.4\n",
       "30  ai1_median_f         0.4\n",
       "31     ai2_ptp_f         0.4\n",
       "32     ai2_min_f         0.4\n",
       "33     ai1_max_b         0.4\n",
       "34     ai2_ptp_b         0.2\n",
       "35     ai2_max_f         0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df.groupby('Feature')['importance'].mean().sort_values(ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train['std_b'].plot.kde()\n",
    "# test['std_b'].plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_fe = ['ai1_kurt_f', 'ai1_ptp_f',\n",
    " 'ai1_kurt_b', 'ai2_mean_f', 'ai1_mean_b', 'ai1_max_f',\n",
    " 'ai2_kurt_b', 'ai2_std_f', 'ai2_std_b', 'ai1_min_f',\n",
    " 'ai1_std_b', 'ai1_mean_f', 'std_f', 'ai2_mode_b']\n",
    "X_train = train[col_fe].copy()\n",
    "y_train = train['result'].copy()\n",
    "X_test = test[col_fe].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "recall_score :  [1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"1226,18,0.1:4000\"\"\"\n",
    "\"\"\"222,21,0.1\"\"\"\n",
    "K = 5\n",
    "seed = 1226\n",
    "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=seed)\n",
    "oof = np.zeros(len(X_train))\n",
    "predictions = np.zeros(len(X_test))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "score = []\n",
    "prec_score = []\n",
    "min_p = []\n",
    "for i, (train_index, val_index) in enumerate(skf.split(X_train,y_train)):\n",
    "    print(\"fold {}\".format(i))\n",
    "    X_tr, X_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_tr, y_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    clf = AdaBoostClassifier(n_estimators=23, learning_rate=0.1)\n",
    "    clf.fit(X_tr,y_tr)\n",
    "    oof[val_index] = clf.predict_proba(X_val)[:, 1]\n",
    "    r_score = lgb_recall_score(y_val.values, clf.predict_proba(X_val)[:, 1],0.0045)#0.23\n",
    "#     p_score = lgb_precision_score(y_val.values, clf.predict_proba(X_val)[:, 1],0.0045)\n",
    "    score.append(r_score)\n",
    "#     prec_score.append(p_score)\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = col_fe\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "    fold_importance_df[\"fold\"] = i + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    predictions += clf.predict_proba(X_test)[:, 1]\n",
    "print('recall_score : ', score)\n",
    "# print('precision_score : ', prec_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4200\n",
      "1    1538\n",
      "Name: result, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"lgbb_4200,lgb_\"\"\"\n",
    "sub = test[['idx']].copy()\n",
    "sub['result'] = predictions\n",
    "sub = sub.sort_values('result').reset_index(drop=True)\n",
    "sub.loc[:4200,'result'] = 0   #lgb  2000:0.3626,3000:0.5439,3200:0.5799,3500:0.6343,3750:0\n",
    "sub.loc[4200:,'result'] = 1\n",
    "sub['result'] = sub['result'].astype(int)\n",
    "# sub.to_csv('../sub/jichu_ada4200.csv', index=False)\n",
    "print(sub['result'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catjj = pd.read_csv('../sub/5385.csv')\n",
    "cat3 = catjj[catjj['result'] == 1]['idx'].tolist()\n",
    "cc = sub[sub['idx'].isin(cat3)]['result']\n",
    "cc[cc==0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ai1_kurt_f</td>\n",
       "      <td>0.321739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ai1_ptp_f</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ai1_kurt_b</td>\n",
       "      <td>0.147826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ai2_mean_f</td>\n",
       "      <td>0.095652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ai2_std_b</td>\n",
       "      <td>0.060870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ai2_kurt_b</td>\n",
       "      <td>0.034783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ai1_std_b</td>\n",
       "      <td>0.034783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ai1_mean_b</td>\n",
       "      <td>0.034783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ai1_max_f</td>\n",
       "      <td>0.026087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ai2_std_f</td>\n",
       "      <td>0.008696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ai1_min_f</td>\n",
       "      <td>0.008696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ai1_mean_f</td>\n",
       "      <td>0.008696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>std_f</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ai2_mode_b</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Feature  importance\n",
       "0   ai1_kurt_f    0.321739\n",
       "1    ai1_ptp_f    0.217391\n",
       "2   ai1_kurt_b    0.147826\n",
       "3   ai2_mean_f    0.095652\n",
       "4    ai2_std_b    0.060870\n",
       "5   ai2_kurt_b    0.034783\n",
       "6    ai1_std_b    0.034783\n",
       "7   ai1_mean_b    0.034783\n",
       "8    ai1_max_f    0.026087\n",
       "9    ai2_std_f    0.008696\n",
       "10   ai1_min_f    0.008696\n",
       "11  ai1_mean_f    0.008696\n",
       "12       std_f    0.000000\n",
       "13  ai2_mode_b    0.000000"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df.groupby('Feature')['importance'].mean().sort_values(ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train_jichu.csv')\n",
    "test = pd.read_csv('../data/test_jichu.csv')\n",
    "for df in [train,test]:\n",
    "    df['std_b'] = df['ai1_std_b'] / df['ai2_std_b']\n",
    "    df['std_f'] = df['ai1_std_f'] / df['ai2_std_f']\n",
    "    df['ai1_ptp_b'] = df['ai1_max_b'] / df['ai1_min_b']\n",
    "    df['ai2_ptp_b'] = df['ai2_max_b'] / df['ai2_min_b']\n",
    "    df['ai1_ptp_f'] = df['ai1_max_f'] / df['ai1_min_f']\n",
    "    df['ai2_ptp_f'] = df['ai2_max_f'] / df['ai2_min_f']\n",
    "#     df['std_ai1_bf'] = df['ai1_std_b'] / df['ai1_std_f']\n",
    "#     df['std_ai2_bf'] = df['ai2_std_b'] / df['ai2_std_f']\n",
    "    df['ratio_b'] = df['ai1_ptp_b'] / df['ai2_ptp_b']\n",
    "    df['area_b'] = df['ai1_ptp_b'] * df['ai2_ptp_b']\n",
    "#     df['ratio_f'] = df['ai1_ptp_f'] / df['ai2_ptp_f']\n",
    "#     df['area_f'] = df['ai1_ptp_f'] * df['ai2_ptp_f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = [i for i in train.columns if i not in ['idx', 'result']]\n",
    "X_train = train[col].copy()\n",
    "y_train = train['result'].copy().astype(int)\n",
    "X_test = test[col].copy()\n",
    "K = 5\n",
    "seed = 211#2021\n",
    "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  1\n",
      "[01:06:42] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\teval-auc:0.821667\n",
      "Will train until eval-auc hasn't improved in 60 rounds.\n",
      "[50]\teval-auc:0.995\n",
      "[59]\teval-auc:0.995\n",
      "\n",
      "Fold  2\n",
      "[01:06:42] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\teval-auc:0.891667\n",
      "Will train until eval-auc hasn't improved in 60 rounds.\n",
      "[50]\teval-auc:1\n",
      "[59]\teval-auc:1\n",
      "\n",
      "Fold  3\n",
      "[01:06:43] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\teval-auc:0.878333\n",
      "Will train until eval-auc hasn't improved in 60 rounds.\n",
      "[50]\teval-auc:1\n",
      "[59]\teval-auc:1\n",
      "\n",
      "Fold  4\n",
      "[01:06:43] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\teval-auc:0.911667\n",
      "Will train until eval-auc hasn't improved in 60 rounds.\n",
      "[50]\teval-auc:0.993333\n",
      "[59]\teval-auc:0.993333\n",
      "\n",
      "Fold  5\n",
      "[01:06:43] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\teval-auc:0.966667\n",
      "Will train until eval-auc hasn't improved in 60 rounds.\n",
      "[50]\teval-auc:0.993333\n",
      "[59]\teval-auc:0.995\n",
      "recall_score :  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Wall time: 411 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_pred_te_all = 0\n",
    "xgb_auc_mean = 0\n",
    "xgb_auc_mean2 = 0\n",
    "f1 = []\n",
    "score = []\n",
    "prec_score = []\n",
    "oof_xgb = np.zeros(len(X_train))\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X_train,y_train)):\n",
    "    \n",
    "    y_tr, y_val = y_train.iloc[train_index].copy(), y_train.iloc[test_index].copy()\n",
    "    X_tr, X_val= X_train.iloc[train_index,:].copy(), X_train.iloc[test_index,:].copy()\n",
    "    print( \"\\nFold \", i+1)\n",
    "\n",
    "    xgb_tr = xgb.DMatrix(X_tr, y_tr)\n",
    "    xgb_val = xgb.DMatrix(X_val, y_val)\n",
    "    xgb_te = xgb.DMatrix(X_test)\n",
    "    xgb_params = {\n",
    "                      \"objective\": 'reg:logistic',\n",
    "                      \"booster\" : \"gbtree\",\n",
    "#                       \"eta\": 0.1,\n",
    "                      \"max_depth\": 3,#6\n",
    "                      \"subsample\": 0.8,#0.85\n",
    "                      'eval_metric':'auc',#logloss\n",
    "#                       \"colsample_bytree\": 0.7,#0.7\n",
    "                      \"colsample_bylevel\":0.6,#0.8\n",
    "                      'tree_method':'hist',#exact\n",
    "                      'alpha':0.02,                         \n",
    "                      \"thread\":6,\n",
    "                      'silent':True,\n",
    "                      \"seed\": 111\n",
    "                  }\n",
    "    watchlist = [(xgb_val, 'eval')]\n",
    "    xgb_model =xgb.train(xgb_params,\n",
    "                 xgb_tr,\n",
    "                 num_boost_round = 60,#100\n",
    "                 evals =watchlist,\n",
    "                 verbose_eval=50,\n",
    "                 early_stopping_rounds=60#30\n",
    "                        )\n",
    "\n",
    "    pred = xgb_model.predict(xgb_val, ntree_limit=xgb_model.best_ntree_limit)\n",
    "    oof_xgb[test_index] = xgb_model.predict(xgb_val, ntree_limit=xgb_model.best_ntree_limit)\n",
    "#     print( \" auc_model = \", xgb_model.best_score )\n",
    "    r_score = lgb_recall_score(y_val.values, xgb_model.predict(xgb_val, ntree_limit=xgb_model.best_ntree_limit),0.08)#0.23\n",
    "#     p_score = lgb_precision_score(y_val.values, xgb_model.predict(xgb_val, ntree_limit=xgb_model.best_ntree_limit),0.08)\n",
    "    score.append(r_score)\n",
    "#     prec_score.append(p_score)\n",
    "    pred_te = xgb_model.predict(xgb_te, ntree_limit=xgb_model.best_ntree_limit)\n",
    "    xgb_pred_te_all = xgb_pred_te_all + pred_te / K\n",
    "print('recall_score : ', score)\n",
    "# print('precision_score : ', prec_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.042726    418\n",
      "0.042696    281\n",
      "0.043920    180\n",
      "0.042749    159\n",
      "0.043954    152\n",
      "Name: result, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"3640—3600\"\"\"\n",
    "sub = test[['idx']].copy()\n",
    "sub['result'] = xgb_pred_te_all\n",
    "print(sub['result'].value_counts().head())\n",
    "sub = sub.sort_values('result').reset_index(drop=True)\n",
    "sub.loc[:3640,'result'] = 0\n",
    "sub.loc[3640:,'result'] = 1\n",
    "sub['result'] = sub['result'].astype(int)\n",
    "# sub.to_csv('../sub/jichu_xgb3600.csv', index=False)\n",
    "catjj = pd.read_csv('../sub/S1_best_score.csv')#cat,0.66\n",
    "cat3 = catjj[catjj['result'] == 1]['idx'].tolist()\n",
    "cc = sub[sub['idx'].isin(cat3)]['result']\n",
    "cc[cc==0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# xgb.__version__(0.72)\n",
    "# fe_map  = xgb_model.get_fscore()\n",
    "# feature = pd.DataFrame(list(xgb_model.get_fscore()))[0]\n",
    "# values = pd.DataFrame(list(xgb_model.get_fscore()))[0].map(fe_map)\n",
    "# fe_values = pd.DataFrame(feature)\n",
    "# fe_values['value'] = values\n",
    "# fe_values = fe_values.rename(columns={0:'feature'}).sort_values(by = 'value',ascending=False).reset_index(drop = True)\n",
    "# fe_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
